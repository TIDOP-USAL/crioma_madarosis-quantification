# -*- coding: utf-8 -*-
"""
Quantification of facial hair loss from multitemporal images
CRIOMA - TIDOP Research Group, Escuela Politécnica Superior de Ávila

Author: Innes Barbero-García (ines.barbero@usal.es)
"""

import os
import cv2
import torch
import shutil
import subprocess
import numpy as np


from pathlib import Path
import utils


# Base paths (Adjust as needed)
BASE_DIR = "data/"

# External script paths
DAM_NET_SCRIPT = "models/DAM-Net/eyebrow_test.py"
DAM_NET_CONFIG = "models/DAM-Net/config/DAM-Net.toml"
DAM_NET_CHECKPOINT = "models/DAM-Net/checkpoints/DAM-Net/best_model.pth"
R2D2_SCRIPT = "models/r2d2-master/extract_and_match_R2D2.py"
R2D2_MODEL = "models/r2d2-master/models/r2d2_WASF_N16.pt"


# Processing Parameters
CROP_MARGIN = 50
TARGET_WIDTH = 600



def run_pipeline(general_folder):
    """
    Executes the automated computer vision pipeline for objective quantification 
    of periocular hair density changes.
    """
    print("Torch CUDA available:", torch.cuda.is_available())
    
    result_path = 'results_paper_main_component.csv'
    out_csv = open(result_path, 'a')       
    out_csv.write("\nPatient;T1_b_eye_1_; T1_b_eye_2_; T1_l_eye_1_; T1_l_eye_2_; T2_b_eye_1_; T2_b_eye_2_; T2_l_eye_1_; T2_l_eye_2_;T3_b_eye_1_; T3_b_eye_2_; T3_l_eye_1_; T3_l_eye_2_;T3b_b_eye_1_; T3b_b_eye_2_; T3b_l_eye_1_; T3b_l_eye_2_;T4_b_eye_1_; T4_b_eye_2_; T4_l_eye_1_; T4_l_eye_2_;\n")

    for patient_folder in os.listdir(general_folder):
        # Remove previous results to avoid conflicts
        general_path = Path(general_folder)
        for file in (general_path / patient_folder).iterdir():
            if file.name.startswith('out'):
                shutil.rmtree(file)
        
        print("Processing patient:", patient_folder)
        
    
        for el in ["open", "open2", "closed", "closed2"]:
            # Write patient name
            out_csv.write('\n'+patient_folder[-4:] +';')

            ori_image_name= f'{el}.JPG'
            folder_out = os.path.join(general_folder, patient_folder, f"out_{el}/")
            os.makedirs(folder_out, exist_ok=True)
            capture_list = []

            # Copy image to out folder with name as time point, create capture_list containing time points
            # Standardized frontal photographs are acquired per time point (T1-T4).
            for folder in os.listdir(os.path.join(general_folder, patient_folder)):
                if 'out' not in folder: 
                    img_path = os.path.join(general_folder, patient_folder, folder, ori_image_name)
                    if os.path.exists(img_path):
                        capture_list.append(folder)
                        shutil.copy(img_path, os.path.join(folder_out, f"{folder}.JPG"))#Uncomment!
                    else:
                        print(f"Missing {ori_image_name} in {folder}")
                        

            if not all(t in capture_list for t in ['T1', 'T2', 'T3', 'T4']):
                print(f"Missing captures for patient {patient_folder}")
                continue

           
            # Create individual images for time point and eyes save in "images"
            for time_point in capture_list:  
                print(f'timepoint: {time_point}')
                image_name = time_point + '.JPG'
                # Extracts periocular landmarks and regions of interest (ROI).
                eyes_image, eye1_image, eye2_image, ini_eyes_image, ini_eye1_image, ini_eye2_image = utils.extract_eyes(folder_out, image_name)    
                os.makedirs(os.path.join(folder_out + "images"), exist_ok=True)
                # Will have one image for eyebrows (b) and one image for eyelashes (l)    
                shutil.copy(os.path.join(folder_out, time_point + '_eye1.jpg'), os.path.join(folder_out, 'images/' + time_point + '_b_eye1.jpg'))
                shutil.copy(os.path.join(folder_out, time_point + '_eye2.jpg'), os.path.join(folder_out, 'images/' + time_point + '_b_eye2.jpg'))
                shutil.copy(os.path.join(folder_out, time_point + '_eye1.jpg'), os.path.join(folder_out, 'images/' + time_point + '_l_eye1.jpg'))
                shutil.copy(os.path.join(folder_out, time_point + '_eye2.jpg'), os.path.join(folder_out, 'images/' + time_point + '_l_eye2.jpg'))
                
                
            # Process Baseline (T1)
            image1_name = "T1.JPG"
            eyes_image1, eye1_image1, eye2_image1, ini_eyes_image1, ini_eye1_image1, ini_eye2_image1 = utils.extract_eyes(folder_out, image1_name)    
            
            # Generate trimaps for the baseline:
            # Baseline trimaps are generated by geometric aggregation of superior periocular landmarks.
            utils.generate_trimaps_first_image(folder_out, image1_name, eyes_image1, ini_eyes_image1, ini_eye1_image1, ini_eye2_image1)

            # copy images t1 to process separately
            utils.copy_t1_images(folder_out)
            
            # Detection of hair only for first image, it will help generating trimaps for other images
            # Performs trimap-guided deep learning hair segmentation using DAM-Net.
            result = subprocess.call("python " + DAM_NET_SCRIPT + " --config " + DAM_NET_CONFIG + " --checkpoint " + DAM_NET_CHECKPOINT + " --image-dir " + folder_out + 'image1/images'  + " --trimap-dir " + folder_out + '/image1/trimap' + " --output " + folder_out  + "/outputs_detection")
            print('result')
            print(result)
                
            # For rest of time points (excluding first) - Multitemporal Registration
            for time_point in capture_list[1:]:
                image2_name = time_point + ".JPG"
                eyes_image2, eye1_image2, eye2_image2, ini_eyes_image2, ini_eye1_image2, ini_eye2_image2 = utils.extract_eyes(folder_out, image2_name)

                utils.generate_trimaps_other_images(folder_out, time_point, DAM_NET_CHECKPOINT)
                
                image1_eye1 = cv2.imread(os.path.join(folder_out, time_point + '_eye1.JPG'))
                image2_eye1 = cv2.imread(os.path.join(folder_out, time_point + '_eye1.JPG'))
                
                image1_eye2 = cv2.imread(os.path.join(folder_out, time_point + '_eye2.JPG'))
                image2_eye2 = cv2.imread(os.path.join(folder_out, time_point + '_eye2.JPG'))
            
                # 1. Coarse Registration using Landmarks
                # A coarse homography is estimated from periocular landmarks to align the follow-up ROI into the T1 frame.
                h_eye1 = cv2.findHomography(eye1_image2-ini_eye1_image2, eye1_image1-ini_eye1_image1)[0]
                image2_eye1_tr1 = cv2.warpPerspective(image2_eye1, h_eye1, (image1_eye1.shape[1],image1_eye1.shape[0]))

            
                h_eye2 = cv2.findHomography(eye2_image2-ini_eye2_image2, eye2_image1-ini_eye2_image1)[0]
                image2_eye2_tr1 = cv2.warpPerspective(image2_eye2, h_eye2, (image1_eye2.shape[1],image1_eye2.shape[0]))

                cv2.imwrite(folder_out + image2_name[:-4] + "_eye1_tr1.jpg",image2_eye1_tr1)
                cv2.imwrite(folder_out + image2_name[:-4] + "_eye2_tr1.jpg",image2_eye2_tr1)
            
                # 2. Fine Registration using R2D2
                # A second homography uses R2D2 keypoints to correct residual misalignment.
                subprocess.call("python " + R2D2_SCRIPT + " --model " + R2D2_MODEL + " --folder " + folder_out + " --image1 T1_eye1.jpg --image2 " + time_point + "_eye1_tr1.jpg")
                subprocess.call("python " + R2D2_SCRIPT + " --model " + R2D2_MODEL + " --folder " + folder_out + " --image1 T1_eye2.jpg --image2 " + time_point + "_eye2_tr1.jpg")
                matches_file_eye1 = open(folder_out + 'matches_R2D2_T1_eye1_' + time_point + '_eye1_tr1.txt', 'r')
                matches_file_eye2 = open(folder_out + 'matches_R2D2_T1_eye2_' + time_point + '_eye2_tr1.txt', 'r')
                
                
                lines = matches_file_eye1.readlines()
                pts1=[]
                pts2=[]
                for line in lines:
                    coords=line.split()
                    pts2.append([int(round(float(coords[2]))), int(round(float(coords[3])))])
                    pts1.append([int(round(float(coords[0]))), int(round(float(coords[1])))])
                
                pts1=np.array(pts1, dtype='float32')    
                pts2=np.array(pts2) 
                # Calculate Homography 
                h2_eye1, status = cv2.findHomography(pts2, pts1)
                
                image1_eye1 = cv2.imread(folder_out + 'T1_eye1.jpg')
                image2_eye1 = cv2.imread(folder_out + image2_name[:-4] + '_eye1_tr1.jpg')
                # Apply final registration to obtain the refined registered ROI.
                image2_eye1_tr2 = cv2.warpPerspective(image2_eye1_tr1, h2_eye1, (image1_eye1.shape[1],image1_eye1.shape[0]))

                 
                cv2.imwrite(folder_out + 'images/' + time_point + "_l_eye1_tr2.jpg",image2_eye1_tr2)
                cv2.imwrite(folder_out + 'images/' + time_point + "_b_eye1_tr2.jpg",image2_eye1_tr2)

                lines = matches_file_eye2.readlines()
                pts1=[]
                pts2=[]
                for line in lines:
                    coords=line.split()
                    pts2.append([int(round(float(coords[2]))), int(round(float(coords[3])))])
                    pts1.append([int(round(float(coords[0]))), int(round(float(coords[1])))])
                
                pts1=np.array(pts1, dtype='float32')    
                pts2=np.array(pts2) 
                # Calculate Homography 
                h2_eye2, status = cv2.findHomography(pts2, pts1)
                image1_eye2 = cv2.imread(folder_out + 'T1_eye2.jpg')
                image2_eye2 = cv2.imread(folder_out + image2_name[:-4] +'_eye2_tr1.jpg')
                # Apply final registration to obtain the refined registered ROI.
                image2_eye2_tr2 = cv2.warpPerspective(image2_eye2_tr1, h2_eye2, (image1_eye2.shape[1],image1_eye2.shape[0]))

            
            
                cv2.imwrite(folder_out + 'images/' + image2_name[:-4] + "_l_eye2_tr2.jpg",image2_eye2_tr2)
                cv2.imwrite(folder_out + 'images/' + image2_name[:-4] + "_b_eye2_tr2.jpg",image2_eye2_tr2)
  

            # Remove original images
            for file in os.listdir(os.path.join(folder_out, 'images')):
                if not (file.endswith("tr2.jpg") or file.startswith('T1')):
                    os.unlink(os.path.join(folder_out, 'images', file))
                    
                    
            path_out = Path(folder_out)  # Ensures it is Path
            

            # Hair detection for generated images, first remove image 1
            for file in os.listdir(os.path.join(path_out, "images")):
                if file.startswith("T1"):
                    os.remove(os.path.join(path_out, "images", file))
                    
            # Executes the DAM-Net segmentation on the registered images.
            result = subprocess.call("python " + DAM_NET_SCRIPT + " --config " + DAM_NET_CONFIG + " --checkpoint " + DAM_NET_CHECKPOINT + " --image-dir " + folder_out + '/images '  + " --trimap-dir " + folder_out + '/trimaps ' + " --output " + folder_out  + "/outputs_detection")
            print(result)
            print(f'Patient: {patient_folder}')
            
            # Rename image 1
            os.rename(path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_b_eye1.jpg", path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_b_eye1_tr2.jpg")
            os.rename(path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_b_eye2.jpg", path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_b_eye2_tr2.jpg")
            os.rename(path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_l_eye1.jpg", path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_l_eye1_tr2.jpg")
            os.rename(path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_l_eye2.jpg", path_out / "outputs_detection" / "DAM_Net_best_model.pth" / "T1_l_eye2_tr2.jpg")
            
            # Final Quantification
            for time_point in ["T1", "T2", "T3", "T3b", "T4"]:
                try:
                    if time_point in capture_list:
                        # Base output path
                        model_outputs_path = path_out / "outputs_detection" / "DAM_Net_best_model.pth"
                        
                        # Image list
                        eye_files = [
                            f"{time_point}_b_eye1_tr2.jpg",
                            f"{time_point}_b_eye2_tr2.jpg",
                            f"{time_point}_l_eye1_tr2.jpg",
                            f"{time_point}_l_eye2_tr2.jpg"
                        ]
                        
                        for eye_file in eye_files:
                            img_path = model_outputs_path / eye_file
                        
                            if not img_path.exists():
                                print(f"⚠️ File not found: {img_path}")
                                out_csv.write(" 0;")
                                continue
                            
                            # Apply morphological filtering to isolate hair structures from noise.
                            img = utils.filter_main_component(img_path)
                            # print(img_path)
                            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

                            # 2. Binarize (bright areas)
                            # Thresholding to obtain the final binary mask.
                            _, img = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)

                            # print('Filtering finished')
                            
                        
                            if img is None:
                                out_csv.write(" 0;")
                            else:
                                # cv2.imwrite(img_path, img)
                                # The number of foreground pixels represents the periocular hair density.
                                out_csv.write(f" {np.sum(img > 0)};")
                    else: # For missed time points
                        out_csv.write(" ; ; ; ;")
                except:
                    continue
            out_csv.flush() 

        
    out_csv.close()
            
        
if __name__ == "__main__":
    run_pipeline(BASE_DIR )